<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Nishanth's blogs - General</title><link href="https://nishanth-r.github.io/vector-db/" rel="alternate"></link><link href="https://nishanth-r.github.io/vector-db/feeds/general.atom.xml" rel="self"></link><id>https://nishanth-r.github.io/vector-db/</id><updated>2025-03-16T00:00:00+05:30</updated><entry><title>Building a Vector Database: My Journey from Scratch ðŸš€</title><link href="https://nishanth-r.github.io/vector-db/scratch.html" rel="alternate"></link><published>2025-03-16T00:00:00+05:30</published><updated>2025-03-16T00:00:00+05:30</updated><author><name>Nishanth Ravindran</name></author><id>tag:nishanth-r.github.io,2025-03-16:/vector-db/scratch.html</id><summary type="html">&lt;h1&gt;Building a Vector Database: My Journey from Scratch ðŸš€&lt;/h1&gt;
&lt;h2&gt;From Application Developer to Database Builder&lt;/h2&gt;
&lt;p&gt;For over a decade, I've been immersed in application development, often relying on others for the underlying infrastructure.  I've navigated countless system design and data structure interviews, always harboring a secret desire: to build something fundamental â€¦&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Building a Vector Database: My Journey from Scratch ðŸš€&lt;/h1&gt;
&lt;h2&gt;From Application Developer to Database Builder&lt;/h2&gt;
&lt;p&gt;For over a decade, I've been immersed in application development, often relying on others for the underlying infrastructure.  I've navigated countless system design and data structure interviews, always harboring a secret desire: to build something fundamental from the ground up.  This project is my chance to finally put that knowledge into action!&lt;/p&gt;
&lt;h2&gt;Diving into the World of Vector Databases&lt;/h2&gt;
&lt;p&gt;This is where I channel my creative energy â€“ into building a functional vector database.  My fascination began with a quirky experiment using &lt;code&gt;sqlite&lt;/code&gt; (more of a hack than a true database!), but this time it's different.  The goal: to create a system that seamlessly handles diverse text data and stores it as vector embeddings.&lt;/p&gt;
&lt;h2&gt;What's a Vector Database, Anyway?&lt;/h2&gt;
&lt;p&gt;Let's get the basics straight. According to Google Gemini:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"A vector database is a database specifically designed to store, manage, and query vector embeddings for similarity search and retrieval."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="img1.jpg" src="img1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;In simpler terms, it excels at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Storing and managing large arrays of floating-point values (vectors).&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performing efficient similarity searches â€“ finding data points that are "close" to a given query.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Database Fundamentals: Keeping it Simple&lt;/h2&gt;
&lt;p&gt;Building a database from scratch is a formidable challenge. It demands performance, reliability, security, and scalability.  At its core, a database needs to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Be fast.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Offer a simple data storage interface.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ensure reliable and repeatable operations.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scale effectively.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These requirements often clash, hinting at the complexities of the CAP theorem.  However, with smart design choices, we can achieve a balance.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Speeding Things Up: B-Tree Indexing&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Imagine a library with an incredibly detailed card catalog. That's the essence of a B-tree index! Gemini explains it best:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Imagine a library with a super organized card catalog, but instead of just author or title, it's for every single word in every book! That's kinda like a B-tree index. Think of it as a multi-level directory. At the top, you have broad categories, like "A-M" and "N-Z". Each of those points to more specific sub-categories, like "Apple to Bat" and "Bear to Cat". Eventually, you hit the "leaf" level, which tells you exactly where in the book (or database) that word (or piece of data) is located.&lt;/p&gt;
&lt;p&gt;So, when you search for "banana", the database doesn't have to read every single book. It quickly hops from "A-M" to "Bear to Cat", and then directly to the page where "banana" is hiding. It's like a super-fast treasure map for your data, keeping everything sorted and easily accessible, making lookups incredibly efficient."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Essentially, B-trees drastically reduce search times for large datasets.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Caching: Keeping Hot Data Close&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Caching involves storing frequently accessed data in RAM for faster retrieval.  But it raises questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How often should caches be updated?&lt;/li&gt;
&lt;li&gt;How do we handle cache replication?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ðŸ¤”ðŸ¤”ðŸ¤” These are challenges we'll tackle later!&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Scaling with Sharding&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Sharding breaks down large datasets into smaller chunks, distributed across multiple servers.  While it might seem counterintuitive (trading disk reads for network calls), it's essential for scaling beyond the limits of a single server.  This ensures the database can handle increasing loads effectively.&lt;/p&gt;</content><category term="General"></category><category term="database"></category><category term="develop"></category><category term="journey"></category></entry></feed>